{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RR2C1HnNoD6a",
        "2I0McYXOoE4a",
        "KF5Is3GFoJ3K",
        "t-fYa9gLs9Wl",
        "Z0h5uSarrOPr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How the Ren'Py Auto-Translator Works ⚙️\n",
        "\n",
        "This notebook automates the translation of Ren'Py (`.rpy`) script files by using large language models (LLMs). It's designed to read your game's text, send it to an AI for translation, and then reassemble it into a new, translated `.rpy` file while preserving the original code structure and formatting.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. Setup and Configuration\n",
        "\n",
        "First, the notebook sets up the environment. You provide **API keys** for the API you want to use (like Google AI Studio or Google Vertex (Not tested) or an OpenAI-compatible APIs).\n",
        "\n",
        "Next, you configure the translation by defining:\n",
        "* **Source and Target Languages**: You specify the original language of the script and the language you want to translate it into (e.g., \"English\" to \"Persian\").\n",
        "* **Prompts**:\n",
        "    * The **System Prompt** acts as the main instruction manual for the AI. It tells the model its role (an expert Ren'Py translator) and gives it strict rules to follow, such as preserving code, formatting tags (`{b}`, `\\n`), and special characters.\n",
        "    * The **Game-Specific Prompt** is where you provide context about your game. This includes character names, desired tone, and translations for recurring terms, which helps the AI produce a more accurate and consistent translation.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Processing and Chunking\n",
        "\n",
        "Once you provide your input `.rpy` file, the notebook doesn't send the entire file to the AI at once. Large files can exceed the model's context limit.\n",
        "\n",
        "Instead, it performs two key steps:\n",
        "1.  **Preprocessing**: It reads your file and identifies all the translatable blocks of text (dialogue and UI elements).\n",
        "2.  **Chunking**: It intelligently groups these blocks into smaller **chunks**. Each chunk is sized to fit within the AI model's maximum input token limit, ensuring that no request is too large for the model to handle.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. The Translation Loop\n",
        "\n",
        "The core of the notebook is the translation loop, which processes one chunk at a time:\n",
        "\n",
        "1.  **API Call**: It sends a chunk of your game's text to the selected AI model, along with the detailed prompts you configured.\n",
        "2.  **AI Translation**: The AI follows the instructions to translate only the dialogue and UI text within the chunk, leaving all code, comments, and formatting tags intact.\n",
        "3.  **Validation**: After receiving the translation, the notebook performs a quick check to ensure the output is valid. It verifies that the number of translation blocks is correct and that the structure hasn't been corrupted.\n",
        "4.  **Retry on Failure**: If a translation fails validation or if there's an API error, the notebook will automatically **retry** the request a few times. It may slightly increase the \"temperature\" (randomness) on subsequent tries to get a better result.\n",
        "\n",
        "This process repeats until all chunks have been successfully translated.\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Final Output\n",
        "\n",
        "After the loop finishes, the notebook takes all the translated chunks and stitches them back together in the correct order. The final, complete translation is then saved to a new `.rpy` file, which is named using the target language (e.g., `input_file_Persian.rpy`). You can then download this file and use it in your Ren'Py project."
      ],
      "metadata": {
        "id": "KNDWkrZc4RZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "fisxSBCl8A6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJHkES49PFPH"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set API Keys here\n",
        "# from google.colab import userdata\n",
        "# API_KEY = userdata.get(\"api_key\")\n",
        "\n",
        "GEMINI_API_KEY = \"\" #@param {\"type\": \"string\"}\n",
        "OPENAI_API_KEY = \"\" #@param {\"type\": \"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6q7TlfTAPN0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Either run **Gemini with Google Client**, or **OpenAI-compatible API**."
      ],
      "metadata": {
        "id": "vSM1PBoDnhnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google API"
      ],
      "metadata": {
        "id": "RR2C1HnNoD6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define Google Client (NO JSON SCHEMA SUPPORT YET)\n",
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "from google.genai import types\n",
        "\n",
        "GOOGLE_MODEL_NAME = \"gemini-2.0-flash\" # @param [\"gemini-2.5-pro\",\"gemini-2.5-flash\",\"gemini-2.0-flash\"] {\"allow-input\":true}\n",
        "MAX_OUTPUT_TOKENS = 6144 #@param {\"type\": \"integer\"}\n",
        "\n",
        "google_safety_settings = [\n",
        "    types.SafetySetting(\n",
        "        category=types.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=types.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=types.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=types.HarmCategory.HARM_CATEGORY_CIVIC_INTEGRITY,\n",
        "        threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
        "    ),\n",
        "    types.SafetySetting(\n",
        "        category=types.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=types.HarmBlockThreshold.BLOCK_NONE,\n",
        "    )\n",
        "]\n",
        "\n",
        "def create_completion_with_client(user_prompt, system_prompt, temperature=0.2):\n",
        "    completion = client.models.generate_content(\n",
        "        model=GOOGLE_MODEL_NAME,\n",
        "        contents=[user_prompt],\n",
        "        config=types.GenerateContentConfig(\n",
        "            system_instruction=system_prompt,\n",
        "            temperature=temperature,\n",
        "            max_output_tokens=MAX_OUTPUT_TOKENS,\n",
        "            safety_settings=google_safety_settings,\n",
        "        ),\n",
        "    )\n",
        "    return completion.text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JkgBXADEoCNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI-Compatible API"
      ],
      "metadata": {
        "id": "2I0McYXOoE4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define OpenAI Client\n",
        "from openai import OpenAI\n",
        "\n",
        "API_URL = \"https://openrouter.ai/api/v1\" #@param {\"type\": \"string\", \"allow-input\": true} [\"https://openrouter.ai/api/v1\", \"https://api.cohere.ai/compatibility/v1\"]\n",
        "MODEL_NAME = \"meta-llama/llama-4-maverick:free:nitro\" # @param [\"meta-llama/llama-4-maverick:free:nitro\",\"command-r-plus-04-2024\",\"command-r7b-12-2024\",\"command-r-08-2024\",\"command-a-03-2025\"] {\"allow-input\":true}\n",
        "MAX_OUTPUT_TOKENS = 8192 #@param {\"type\": \"integer\"}\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= OPENAI_API_KEY,\n",
        "    base_url= API_URL,\n",
        ")\n",
        "\n",
        "my_safety_settings = [\n",
        "    # {\"category\": \"HARM_CATEGORY_UNSPECIFIED\", \"threshold\": \"BLOCK_NONE\"},\n",
        "    {\"category\": \"HARM_CATEGORY_UNSPECIFIED\", \"threshold\": \"OFF\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"OFF\"},\n",
        "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"OFF\"},\n",
        "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"OFF\"},\n",
        "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"OFF\"},\n",
        "    {\"category\": \"HARM_CATEGORY_CIVIC_INTEGRITY\", \"threshold\": \"OFF\"},\n",
        "]\n",
        "google_safety_settings = {\n",
        "    \"safety_settings\": my_safety_settings\n",
        "}\n",
        "\n",
        "def is_google_model(model_name):\n",
        "    return \"google/\" in model_name.lower() or 'gemini' in model_name.lower()\n",
        "\n",
        "def create_completion_with_client(user_prompt, system_prompt, json_schema=None, extra_body=None, temperature=0.2):\n",
        "    try:\n",
        "        completion = client.chat.completions.create(\n",
        "            model=MODEL_NAME,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            temperature=temperature,\n",
        "            max_tokens=MAX_OUTPUT_TOKENS,\n",
        "            response_format = { \"type\": \"json_object\", \"schema\": json_schema } if json_schema is not None else None,\n",
        "            stream=False,\n",
        "            extra_body=extra_body if extra_body is not None else google_safety_settings if is_google_model(MODEL_NAME) else None\n",
        "        )\n",
        "        return completion.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "fFXwZfcknlNV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts and values"
      ],
      "metadata": {
        "id": "KF5Is3GFoJ3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Languages and SYSTEM PROMPT\n",
        "#@markdown Source and Target languages, should be exactly the same as the ones used in Renpy, and `.rpy` translation files.\n",
        "SOURCE_LANGUAGE = \"English\" #@param {\"type\": \"string\", \"allow-input\": true}\n",
        "TARGET_LANGUAGE = \"Persian\" #@param {\"type\": \"string\", \"allow-input\": true}\n",
        "#@markdown This general system prompt is good enough for most use cases, but feel free to change it.\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert AI translator specializing in translating visual novel games from [SRC_LANG] to [TGT_LANG].\n",
        "Your task is to process the provided Ren'Py translation segment and output the complete segment with the [SRC_LANG] strings translated into [TGT_LANG].\n",
        "\n",
        "**Input Format:**\n",
        "The file contains two types of translation blocks:\n",
        "\n",
        "1.  **Dialogue Lines:**\n",
        "    These blocks start with `translate [TGT_LANG] label_identifier:`. They sometimes include CHAR_NAME which may look like this: mc, Teller, etc.\n",
        "    Example:\n",
        "    translate [TGT_LANG] label_identifier:\n",
        "\n",
        "        CHAR_NAME \"dialogue line with {b}tags{/b} and \\n newlines.\"\n",
        "    For these blocks, you must translate **only** the string.\n",
        "\n",
        "2.  **UI/Menu Strings (under `translate [TGT_LANG] strings:`):**\n",
        "    These blocks appear under a line `translate [TGT_LANG] strings:`.\n",
        "    Example:\n",
        "    old \"[SRC_LANG] UI string (with context).\"\n",
        "    new \"[SRC_LANG] UI string (with context).\"\n",
        "    For these blocks, you must translate **only** the string following the `new` keyword.\n",
        "\n",
        "**Key Instructions:**\n",
        "1.  **Target Language:** For this task, Target Language is [TGT_LANG]. The Source Language is [SRC_LANG].\n",
        "2.  **Accurate and Natural Translation:** Translate the text accurately and naturally into Persian, ensuring the translation is appropriate for the context.\n",
        "3.  **Preserve Structure and Formatting:**\n",
        "    *   You MUST preserve the entire original structure, including any comments  (lines starting with `#`) if included, `translate` lines, `old` lines, keywords (like `translate`, `old`, `new`), colons, quotation marks, and existing indentation.\n",
        "    *   Your output should be the complete segment, modified only with the translated text in the designated places.\n",
        "4.  **Handle Special Characters and Tags:**\n",
        "    *   **Newline Characters (`\\n`):** These must be preserved and placed correctly within the translated Persian string to reflect the original line breaks.\n",
        "    *   **Ren'Py Formatting Tags (e.g., `{b}`, `{/b}`, `{i}`, `{/i}`):** These tags must be preserved. In the translated string, they should surround the Persian equivalent of the text that was originally tagged in [SRC_LANG]. For example, if \"It's {b}YOU{/b} who should enjoy\" is the source, the Persian translation should include `{b}` and `{/b}` around the translation of \"YOU\".\n",
        "    *   **Percentage Signs (`%%`):** Preserve these as they appear (e.g., `50%%`). If Persian has a different convention for percentages in this context, apply the correct Persian formatting.\n",
        "    *   **Other Game-Specific Placeholders:** If you encounter any other placeholders (e.g., `[player_name]`), they should generally be kept as-is unless the context implies they represent a translatable concept.\n",
        "5.  **Contextual Clues in Parentheses:**\n",
        "    *   Text within parentheses, such as `(This will be your name)`, `(Sincere)`, `(Unlocks Athletic trait)`, or `(Change name)`, often provides important context or describes an action/choice. This text **must also be translated** into Persian.\n",
        "6.  **Consistency:** Maintain consistent terminology for repeated game concepts or interface elements throughout the translation.\n",
        "\n",
        "**Output:**\n",
        "Your output should be the complete Ren'Py translation segment, with only the specified [SRC_LANG] strings replaced by their [TGT_LANG] (Persian) translations. Do not add any conversational text, introductions, or explanations outside of the Ren'Py file structure itself.\n",
        "\n",
        "[EXAMPLES]\n",
        "\n",
        "Now, please process the input I provide according to these instructions.\n",
        "\"\"\"\n",
        "\n",
        "#@markdown Also provide your own Examples in here.\n",
        "EXAMPLES = \"\"\"**Example of processing a dialogue line:**\n",
        "Source Input:\n",
        "translate Persian start_d6b3d5a6:\n",
        "\n",
        "    # \"If you prefer to go in blind without hints such as these it's ok too.\\nIt's {b}YOU{/b} who should enjoy the game after all.\"\n",
        "    \"If you prefer to go in blind without hints such as these it's ok too.\\nIt's {b}YOU{/b} who should enjoy the game after all.\"\n",
        "\n",
        "Expected Persian Output:\n",
        "translate Persian start_d6b3d5a6:\n",
        "\n",
        "    # \"If you prefer to go in blind without hints such as these it's ok too.\\nIt's {b}YOU{/b} who should enjoy the game after all.\"\n",
        "    \"اگر ترجیح می‌دهید بدون راهنمایی‌هایی از این قبیل به صورت کورکورانه پیش بروید نیز اشکالی ندارد.\\nدر نهایت این {b}شما{/b} هستید که باید از بازی لذت ببرید.\"\n",
        "\n",
        "\n",
        "**Example of processing a UI/Menu string:**\n",
        "Source Input:\n",
        "    # game/script.rpy:494\n",
        "    old \"Yes, speaking. (This will be your name)\"\n",
        "    new \"Yes, speaking. (This will be your name)\"\n",
        "\n",
        "Expected Persian Output:\n",
        "    # game/script.rpy:494\n",
        "    old \"Yes, speaking. (This will be your name)\"\n",
        "    new \"بله، خودم هستم. (اسم شما این خواهد بود)\"\n",
        "\"\"\"\n",
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[SRC_LANG]\", SOURCE_LANGUAGE)\n",
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[TGT_LANG]\", TARGET_LANGUAGE)\n",
        "SYSTEM_PROMPT = SYSTEM_PROMPT.replace(\"[EXAMPLES]\", EXAMPLES)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "18JP5VvHqC4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How to Create a Game-Specific System Prompt\n",
        "\n",
        "This guide helps you generate a high-quality `GAME_SPECIFIC_PROMPT` by using an LLM to analyze your game's script.\n",
        "\n",
        "#### Step 1: Gather Game Scripts\n",
        "\n",
        "Collect the text that the AI will analyze.\n",
        "\n",
        "*   **For small games:** If your project isn't too large, you can give all your `.rpy` script files directly to an LLM model.\n",
        "*   **For larger games:** To avoid exceeding the AI's context limit, select representative samples:\n",
        "    *   Dialogue-heavy scripts to capture character voices.\n",
        "    *   Narration and main character (mc) thoughts to define the game's tone.\n",
        "    *   UI text from files like `screens.rpy`.\n",
        "\n",
        "#### Step 2: Generate the Guide with a Meta-Prompt\n",
        "\n",
        "Use the template below to instruct a model with larger context length (like Gemini 2.5 Pro) to create your guide.\n",
        "\n",
        "**Copy and paste this into the AI:**\n",
        "\n",
        "```text\n",
        "Analyze the provided Ren'Py script and write a \"Translation Guide\" for translating from [Source Language] to [Target Language]. The guide must be a structured Markdown file with the following sections:\n",
        "\n",
        "1.  **Game Overview & Tone:** General tone, narrator's style, and formality level.\n",
        "2.  **Character Guide:** A table listing each character's name, personality, and speaking style.\n",
        "3.  **Glossary of Key Terms:** A table of recurring game-specific terms, locations, or items.\n",
        "4.  **UI/Menu Text Style:** A brief description of the style for UI text.\n",
        "```\n",
        "\n",
        "**Before running:**\n",
        "*   Replace `[Source Language]` and `[Target Language]`.\n",
        "*   Paste your collected script from Step 1 at the end.\n",
        "\n",
        "#### Step 3: Review and Finalize\n",
        "\n",
        "The AI's output is a **draft**, not a final product. Your review is essential.\n",
        "\n",
        "*   **Correct** any errors in the AI's analysis of tone or characters.\n",
        "*   **Add** any missing terms, characters, or context you know is important.\n",
        "*   **Fill in** any suggested translations in the glossary.\n",
        "*   **Clean up** and remove any irrelevant text.\n",
        "\n",
        "The final, edited text is your `GAME_SPECIFIC_PROMPT`. Copy it directly into the Colab notebook."
      ],
      "metadata": {
        "id": "LZ23sB_x6PZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GAME SPECIFIC PROMPT\n",
        "#@markdown Enter your game-specific system prompt here.\n",
        "GAME_SPECIFIC_PROMPT = \"\"\"## \"My Awesome Game\" - Translation Guide\n",
        "\n",
        "**Game Overview & Tone:**\n",
        "*   **General Tone:** A slice-of-life high school drama with comedic elements. The tone is generally informal and modern.\n",
        "*   **Dialogues:** Use informal language for conversations between students. Use formal language when students talk to teachers.\n",
        "*   **Narrator (mc's thoughts):** The narration is introspective, personal, and sometimes sarcastic. The translation should reflect this inner monologue.\n",
        "\n",
        "**Character Guide:**\n",
        "\n",
        "| Character Name/ID | Personality & Role                        | Speaking Style                                       |\n",
        "| :---------------- | :---------------------------------------- | :--------------------------------------------------- |\n",
        "| `mc` / `[name]`   | The protagonist. Can be witty or sincere. | Varies by player choice, but generally modern and direct. |\n",
        "| `jess`            | The energetic and cheerful best friend.   | Uses a lot of slang, exclamation marks, and is very expressive. |\n",
        "| `mr_harrison`     | The strict but fair history teacher.      | Speaks formally, uses complex vocabulary. Always polite. |\n",
        "| `???`             | A mysterious character.                   | Speaks in short, cryptic sentences.                  |\n",
        "\n",
        "**Glossary of Key Terms:**\n",
        "\n",
        "| English Term             | Target Translation | Notes                                      |\n",
        "| :----------------------- | :------------------ | :----------------------------------------- |\n",
        "| The Sunstone             | The Sunstone        | A key item in the story. Keep in English.  |\n",
        "| Everwood High            | Everwood High       | The name of the school.                    |\n",
        "| The \"Glimmer\"            | The \"Glimmer\"       | A special power some characters have.      |\n",
        "\n",
        "**UI/Menu Text Style:**\n",
        "*   UI text should be clear and concise. For example, \"Settings,\" \"Save Game,\" \"Load Game.\"\n",
        "\n",
        "**Cultural & Idiomatic Notes:**\n",
        "*   The phrase \"break a leg\" appears before a performance. This should be translated to its local equivalent for \"good luck.\"\n",
        "*   Jokes often rely on English puns. These should be localized to be funny in the target language, even if it means changing the joke.\"\"\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y_uCSNSmoxLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get System prompt function\n",
        "def get_system_prompt():\n",
        "    return SYSTEM_PROMPT + \"\\n\" + GAME_SPECIFIC_PROMPT"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hPYlU8zuuyXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get Character Per Token\n",
        "#@markdown Add your own language here, depending on the **language**, and chosen **model**, these values changes, but default values are good estimates for English and Persian for OpenAI, Gemini and Cohere models.\n",
        "#@markdown <br> To obtain this, you can use online tokenizers for your model of choice. <br> For Google models, you can use **Google AI Studio** to get the token count of an input text.\n",
        "def get_char_per_token(lang):\n",
        "    if lang == \"English\":\n",
        "        return 3.75\n",
        "    elif lang == \"Persian\":\n",
        "        return 2.8"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LfR0te6t0gFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set retries and temperature\n",
        "RETRIES_NUM = 3 #@param {\"type\": \"integer\"}\n",
        "DEFAULT_TEMPERATURE = 0.7 # @param {\"type\":\"slider\",\"min\":0,\"max\":2,\"step\":0.05}\n",
        "def get_temperature(tries):\n",
        "    #@markdown You can also adjust temperature based on number of failed tries, for example increase temperature\n",
        "    return DEFAULT_TEMPERATURE"
      ],
      "metadata": {
        "id": "7RZGNtZ2ZycF",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function definitions"
      ],
      "metadata": {
        "id": "t-fYa9gLs9Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Blocks and Chunks functions\n",
        "def get_blocks_from_text(text, trg_lng):\n",
        "    blocks = text.split(f\"translate {trg_lng} \")\n",
        "    return [f\"translate {trg_lng} \" + block for block in blocks]\n",
        "\n",
        "def get_input_token_count(text):\n",
        "    return len(text) // get_char_per_token(SOURCE_LANGUAGE)\n",
        "\n",
        "def get_string_from_chunk(chunk):\n",
        "    return \"\\n\".join(chunk)\n",
        "\n",
        "def get_chunks_to_translate(blocks_to_translate, char_per_token, max_input_token):\n",
        "    if get_input_token_count(get_string_from_chunk(blocks_to_translate)) < max_input_token:\n",
        "        return [blocks_to_translate]\n",
        "\n",
        "    all_chunks = []\n",
        "    current_idx = 0\n",
        "    while current_idx < len(blocks_to_translate):\n",
        "        current_chunk = []\n",
        "        current_size = 0\n",
        "        while current_idx < len(blocks_to_translate) and current_size < max_input_token:\n",
        "            current_chunk.append(blocks_to_translate[current_idx])\n",
        "            current_size += get_input_token_count(blocks_to_translate[current_idx])\n",
        "            current_idx += 1\n",
        "        all_chunks.append(current_chunk)\n",
        "    return all_chunks\n",
        "\n",
        "def get_estimated_input_tokens(MAX_OUTPUT_TOKENS):\n",
        "    # Estimate input tokens based on max output tokens\n",
        "    return MAX_OUTPUT_TOKENS * get_char_per_token(TARGET_LANGUAGE) // (1.2 * get_char_per_token(SOURCE_LANGUAGE))"
      ],
      "metadata": {
        "id": "oeSv1HfKr17M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Replace and Restore Hashes in Translation\n",
        "def replace_hashes_with_placeholders(text, trg_lng):\n",
        "    hash_map = {}\n",
        "    placeholder_counter = 0\n",
        "\n",
        "    BLOCK_ID_REGEX = rf\"(translate {trg_lng} )(\\w+):\"\n",
        "    def replacer(match):\n",
        "        nonlocal placeholder_counter\n",
        "        placeholder = f\"_HASH_{placeholder_counter}\"\n",
        "        hash_map[placeholder] = match.group(2)\n",
        "        placeholder_counter += 1\n",
        "        return f\"{match.group(1)}{placeholder}\"\n",
        "\n",
        "    text_with_placeholders = re.sub(BLOCK_ID_REGEX, replacer, text)\n",
        "    return text_with_placeholders, hash_map\n",
        "\n",
        "def restore_hashes_from_placeholders(text_with_placeholders, hash_map):\n",
        "    restored_text = text_with_placeholders\n",
        "    # Iterate through the map and replace each placeholder with its original hash\n",
        "    # Replacing longest placeholders first can prevent issues if one placeholder is a substring of another,\n",
        "    # though our __HASH__<number>__ format avoids this. Still, sorting is safer.\n",
        "    for placeholder in sorted(hash_map.keys(), key=len, reverse=True):\n",
        "        original_hash = hash_map[placeholder]\n",
        "        restored_text = restored_text.replace(placeholder, original_hash)\n",
        "    return restored_text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ya3eLRUSzK70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Translation Validation functions\n",
        "def is_strings_block_valid(chunk_str, translation):\n",
        "    OLD_NEW_REGEX = r'^\\s*old\\s+\"(?:[^\"\\\\]|\\\\.)*\"\\s+^\\s*new\\s+\"(?:[^\"\\\\]|\\\\.)*\"'\n",
        "    return len(re.findall(OLD_NEW_REGEX, chunk_str, re.MULTILINE)) == len(re.findall(OLD_NEW_REGEX, translation, re.MULTILINE))\n",
        "\n",
        "BLOCK_ID_REGEX = rf\"translate {TARGET_LANGUAGE} (\\w+):\"\n",
        "def is_translation_valid(chunk_str, translation):\n",
        "    chunk_blocks = get_blocks_from_text(chunk_str, TARGET_LANGUAGE)\n",
        "    translation_blocks = get_blocks_from_text(translation, TARGET_LANGUAGE)\n",
        "    if len(chunk_blocks) != len(translation_blocks):\n",
        "        print(f\"Translation Invalid: Original has {len(chunk_blocks)} blocks, but translated has {len(translation_blocks)}\")\n",
        "        return False\n",
        "\n",
        "    chunk_block_ids = set(re.findall(BLOCK_ID_REGEX, \"\".join(chunk_blocks)))\n",
        "    translation_block_ids = set(re.findall(BLOCK_ID_REGEX, \"\".join(translation_blocks)))\n",
        "    if chunk_block_ids != translation_block_ids:\n",
        "        missing_ids = chunk_block_ids - translation_block_ids\n",
        "        extra_ids = translation_block_ids - chunk_block_ids\n",
        "        error_msg = \"Translation Invalid: Block IDs mismatch.\"\n",
        "        if missing_ids:\n",
        "             error_msg += f\" Missing IDs: {missing_ids}.\"\n",
        "        if extra_ids:\n",
        "             error_msg += f\" Extra IDs: {extra_ids}.\"\n",
        "        print(error_msg)\n",
        "        return False\n",
        "\n",
        "    for block in translation_blocks:\n",
        "        content_after_header = block.split(':', 1)[-1] if ':' in block else block\n",
        "        if content_after_header.count('\"') % 2 != 0:\n",
        "            print(f\"Translation Invalid: Unmatched quotes found in block starting with:\\n{block.splitlines()[0]}\")\n",
        "            return False\n",
        "\n",
        "    if \"strings\" in chunk_block_ids:\n",
        "        strings_chunk_block = [block for block in chunk_blocks if f\"translate {TARGET_LANGUAGE} strings:\" in block][0]\n",
        "        strings_translation_block = [block for block in translation_blocks if f\"translate {TARGET_LANGUAGE} strings:\" in block][0]\n",
        "        if not is_strings_block_valid(strings_chunk_block, strings_translation_block):\n",
        "             print(f\"Translation Invalid: 'strings' block old/new pair count mismatch.\")\n",
        "             return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# Translation Post-Processing\n",
        "def postprocess_translation(translation):\n",
        "    # Sometimes the model outputs in ```renpy ... ``` format, so remove it\n",
        "    if translation.count(\"```\") % 2 != 0:\n",
        "        return translation\n",
        "    if \"```renpy\" in translation:\n",
        "        return translation[translation.find(\"```renpy\") + len(\"```renpy\"):translation.rfind(\"```\")].strip()\n",
        "    if \"```\" in translation:\n",
        "        return translation[translation.find(\"```\") + len(\"```\"):translation.rfind(\"```\")].strip()\n",
        "    return translation"
      ],
      "metadata": {
        "id": "G4AnQPXlVVWN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process each file"
      ],
      "metadata": {
        "id": "Z0h5uSarrOPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Input file and Preprocess\n",
        "#@markdown Upload your files, and input the file name you want to process\n",
        "INPUT_FILE = \"input_file.rpy\" #@param {\"type\": \"string\"}\n",
        "orig_text = open(INPUT_FILE, \"r\").readlines()\n",
        "\n",
        "import re\n",
        "# Remove comment lines\n",
        "COMMENT_REGEX = r\"^\\s*#.*$\"\n",
        "orig_text = [line for line in orig_text if not re.match(COMMENT_REGEX, line)]\n",
        "\n",
        "# Join all lines into a single string\n",
        "orig_text = \"\".join(orig_text)\n",
        "\n",
        "blocks_to_translate = get_blocks_from_text(orig_text, TARGET_LANGUAGE)[1:]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XmXe37q4rRUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate max input length and Turn into chunks\n",
        "max_input_tokens = get_estimated_input_tokens(MAX_OUTPUT_TOKENS)\n",
        "print(f\"Max input tokens per chunk: {max_input_tokens}\")\n",
        "\n",
        "chunks_to_translate = get_chunks_to_translate(blocks_to_translate, get_char_per_token(SOURCE_LANGUAGE), max_input_tokens)\n",
        "print(f\"Total number of chunks: {len(chunks_to_translate)}\")\n",
        "print(f\"Total number of (estimated) tokens: {sum([get_input_token_count(get_string_from_chunk(chunk)) for chunk in chunks_to_translate])}\")"
      ],
      "metadata": {
        "id": "7fqJ3a1vzpke",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Reset translated chunks list (Re-run to reset the chunks translation progress)\n",
        "translated_chunks = []"
      ],
      "metadata": {
        "id": "7hSS_5JwX6CL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Translate loop\n",
        "from tqdm import tqdm\n",
        "#@markdown You can use this variable to continue from a chunk if you stopped for any reason\n",
        "from_index = 0 #@param {type:\"integer\"}\n",
        "\n",
        "for i in tqdm(range(from_index, len(chunks_to_translate))):\n",
        "    try:\n",
        "        chunk = chunks_to_translate[i]\n",
        "        chunk_str = get_string_from_chunk(chunk)\n",
        "        chunk_str_processed, hash_map = replace_hashes_with_placeholders(chunk_str, TARGET_LANGUAGE)\n",
        "\n",
        "        tries = 0\n",
        "        system_prompt = get_system_prompt()\n",
        "        while tries < RETRIES_NUM:\n",
        "            temperature = get_temperature(tries)\n",
        "            translation_with_placeholders = create_completion_with_client(chunk_str_processed, system_prompt, temperature=temperature)\n",
        "            if translation_with_placeholders is None:\n",
        "                print(f\"Translation for chunk {i} failed at attempt {tries + 1}/{RETRIES_NUM}: API call returned None.\")\n",
        "                tries += 1\n",
        "                continue\n",
        "            translated_str = restore_hashes_from_placeholders(translation_with_placeholders, hash_map)\n",
        "            translated_str = postprocess_translation(translated_str)\n",
        "            if not is_translation_valid(chunk_str, translated_str):\n",
        "                print(f\"Translation for chunk {i} failed validation at attempt {tries + 1}/{RETRIES_NUM}.\")\n",
        "                print(\"\\nRestored translation (validation failed):\")\n",
        "                print(translated_str[:500] + \"\\n...\\n\" + translated_str[-500:])\n",
        "                print(\"-\" * 100) # Separator\n",
        "                tries += 1\n",
        "                continue\n",
        "            print(f\"Translated chunk {i}.\")\n",
        "            print(translated_str[:500] + \"\\n...\\n\" + translated_str[-500:])\n",
        "            print(\"-\" * 100)\n",
        "            translated_chunks.append(translated_str)\n",
        "            break\n",
        "        else:\n",
        "            print(f\"Translation for chunk {i} failed after {RETRIES_NUM} tries.\")\n",
        "            break\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")"
      ],
      "metadata": {
        "id": "0eGRDEzwzvKk",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Did all chunks translate?\n",
        "print(f\"{len(translated_chunks)}/{len(chunks_to_translate)}\")\n",
        "if len(translated_chunks) < len(chunks_to_translate):\n",
        "    print(\"TRANSLATION FAILED!\")\n",
        "else:\n",
        "    print(\"TRANSLATION S\")"
      ],
      "metadata": {
        "id": "q4K45Ktu6d6o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save to file\n",
        "OUTPUT_FILE = INPUT_FILE.replace(\".rpy\", f\"_{TARGET_LANGUAGE}.rpy\")\n",
        "\n",
        "with open(OUTPUT_FILE, \"w\") as f:\n",
        "    for chunk in translated_chunks:\n",
        "        f.write(chunk.strip() + \"\\n\")"
      ],
      "metadata": {
        "id": "FUXzu4qbR_BI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}